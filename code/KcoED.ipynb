{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 진행상황\n",
    "\n",
    "- 중성색에 대한 알고리즘은 아직 구현하지 아니함.\n",
    "- KOTE 감정범주화에 대응하는 새로운 색상값을 라벨링하는 것으로 연구 방향을 정함.\n",
    "- 106개의 IRI 이미지 형용사는 아직 정리하지 아니함\n",
    "- Blossom 프롬프트 엔지니어링 해야함. inpu text에 대한 일관성 부족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. color mapping\n",
    "#### context engineering 전, dummy를 가지고 색 선정 함수를 정의하고자함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import random\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KOTE 44가지 감정의 긍/부정/중립 기준 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emotions = ['감동/감탄', '고마움', '기대감', '기쁨', '뿌듯함',\n",
    "'신기함/관심', '아껴주는', '안심/신뢰', '존경', '즐거움/신남', '편안/쾌적', '행복', '환영/호의',\n",
    "'흐뭇함(귀여움/예쁨)',\n",
    "]\n",
    "negative_emotions = ['경악', '공포/무서움', '귀찮음', '당황/난처', '부끄러움', '부담/안_내킴', '불쌍함/연민', '불안/걱정', \n",
    "                     '불평/불만', '슬픔', '서러움', '안타까움/실망', '어이없음', '역겨움/징그러움', '의심/불신', '짜증', \n",
    "                     '재미없음', '절망', '죄책감', '증오/혐오', '지긋지긋', '패배/자기혐오', '한심함', '화남/분노', '힘듦/지침', '분노']\n",
    "neutral_emotions = ['깨달음', '놀람', '비장함', '우쭐댐/무시함']\n",
    "\n",
    "no_emotion = ['없음']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_emotions_contrast = {'불쌍함/연민': 0.44,\n",
    "'불안/걱정': 0.56,\n",
    "'서러움': 0.51,\n",
    "'슬픔': 0.7,\n",
    "'아껴주는' : 0.47,\n",
    "'안타까움/실망': 0.31,\n",
    "'없음': 0.8,\n",
    "'기쁨':0.6\n",
    "}\n",
    "\n",
    "result_emotions_similar = {'불쌍함/연민': 0.44,\n",
    "'불안/걱정': 0.56,\n",
    "'서러움': 0.51,\n",
    "'슬픔': 0.7,\n",
    "'아껴주는' : 0.47,\n",
    "'안타까움/실망': 0.31,\n",
    "'없음': 0.8,\n",
    "'죄책감':0.6\n",
    "}\n",
    "\n",
    "result_emotions_similaremotion_contrastcolor = {'불쌍함/연민': 0.44,\n",
    "'불안/걱정': 0.56,\n",
    "'서러움': 0.51,\n",
    "'슬픔': 0.7,\n",
    "'아껴주는' : 0.47,\n",
    "'안타까움/실망': 0.31,\n",
    "'없음': 0.8,\n",
    "'분노':0.6\n",
    "}\n",
    "\n",
    "result_IRI = '사랑스러운'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KCoED 데이터셋 & IRI 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 경로\n",
    "file_path = \"../data/korean emtion-color dataset 2.0 - SUM.csv\"\n",
    "# 파일 읽기 (처음엔 컬럼명을 무시하고 불러오기)\n",
    "df_raw = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# 첫 번째 행을 컬럼명으로 지정\n",
    "df_raw.columns = df_raw.iloc[1]\n",
    "df = df_raw[2:]  # 첫 행은 이제 컬럼으로 사용했으니 제외\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path_IRI = \"../data/임이로_학위논문_korean emtion-color dataset 2.0 - IRI-형용사스케일.csv\"\n",
    "# 파일 읽기 (처음엔 컬럼명을 무시하고 불러오기)\n",
    "df_raw_IRI = pd.read_csv(file_path_IRI, header=None)\n",
    "\n",
    "# 첫 번째 행을 컬럼명으로 지정\n",
    "df_raw_IRI.columns = df_raw_IRI.iloc[1]\n",
    "df_IRI = df_raw_IRI[2:]  # 첫 행은 이제 컬럼으로 사용했으니 제외\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path_IRI_colors = \"../data/임이로_학위논문_korean emtion-color dataset 2.0 - IRI-배색스케일.csv\"\n",
    "# 파일 읽기 (처음엔 컬럼명을 무시하고 불러오기)\n",
    "df_raw_IRI_colors = pd.read_csv(file_path_IRI_colors, header=None)\n",
    "\n",
    "# 첫 번째 행을 컬럼명으로 지정\n",
    "df_raw_IRI_colors.columns = df_raw_IRI_colors.iloc[1]\n",
    "df_IRI_colors = df_raw_IRI_colors[2:]  # 첫 행은 이제 컬럼으로 사용했으니 제외\n",
    "\n",
    "# ----------------------------------------\n",
    "# 색상약호가 'White' 또는 'Black'인 행 제거\n",
    "# ----------------------------------------\n",
    "\n",
    "# '색상약호' 컬럼에 NaN이 있을 수 있으므로 fillna 처리\n",
    "df_IRI_colors = df_IRI_colors[~df_IRI_colors['색상약호'].fillna('').isin(['White', 'Black'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_481/2318276721.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: list(g['형용사']))\n"
     ]
    }
   ],
   "source": [
    "# 필요한 열만 추출 ('형용사군', '형용사id', '형용사')\n",
    "adjective_df = df_IRI[['형용사군', '형용사id', '형용사']].dropna()\n",
    "\n",
    "# 형용사id를 숫자로 정리 (필요한 경우)\n",
    "adjective_df['형용사id'] = adjective_df['형용사id'].astype(int)\n",
    "\n",
    "# 형용사군별로 그룹화하여 리스트로 변환\n",
    "grouped_adjectives = (\n",
    "    adjective_df.groupby('형용사군')\n",
    "    .apply(lambda g: list(g['형용사']))\n",
    "    .to_dict()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주감정/보조감정에 대해 KCoED데이터셋에서 주색, 보조색을 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 출력 값 전처리 : 없음을 제거, 감정 범주화에 해당하지 않는 감정 제거 ex) 한심함\n",
    "def filter_emotions(result_emotions, result_IRI):\n",
    "    # Filter out the '없음' key\n",
    "    filtered_emotions = {key: value for key, value in result_emotions.items() if key != '없음'}\n",
    "    \n",
    "    # Sort emotions by their values in descending order\n",
    "    sorted_emotions = sorted(filtered_emotions.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Extract the keys of the top two emotions\n",
    "    top_two_emotions = [sorted_emotions[0][0], sorted_emotions[1][0], result_IRI] if len(sorted_emotions) >= 2 else []\n",
    "    \n",
    "    return top_two_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['슬픔', '기쁨', '사랑스러운'] ['슬픔', '죄책감', '사랑스러운'] ['슬픔', '분노', '사랑스러운']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "## 주-보조 감정은 감정 분류 모델(KPoEM)에서, 형용사는 LLM모델이 반환.\n",
    "top_emotions_contrast = filter_emotions(result_emotions_contrast, result_IRI)\n",
    "top_emotions_similar = filter_emotions(result_emotions_similar, result_IRI)\n",
    "top_emotions_similaremotion_contrastcolor = filter_emotions(result_emotions_similaremotion_contrastcolor, result_IRI)\n",
    "print(top_emotions_contrast, top_emotions_similar, top_emotions_similaremotion_contrastcolor)  # Output: ['슬픔', '기쁨']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize the emotion\n",
    "def categorize_emotion(primary_emotion, secondary_emotion):\n",
    "    # 감정 사전 정의 (예시, 필요에 따라 확장 가능)\n",
    "\n",
    "    # 내부 분류 함수\n",
    "    def classify(emotion):\n",
    "        if emotion in positive_emotions:\n",
    "            return \"positive\"\n",
    "        elif emotion in negative_emotions:\n",
    "            return \"negative\"\n",
    "        elif emotion in neutral_emotions:\n",
    "            return \"neutral\" # 아직 처리 안함.\n",
    "        else:\n",
    "            return \"no_emotion\" #아직 처리 안함.\n",
    "    \n",
    "    def handle_neutral_case(primary_emotion, secondary_emotion):\n",
    "        # 감정이 'neutral'인 경우는 별도의 로직으로 처리\n",
    "        if primary_emotion == \"neutral\" or secondary_emotion == \"neutral\":\n",
    "            return \"배색3\"\n",
    "\n",
    "    # 각각 분류\n",
    "    primary_category = classify(primary_emotion)\n",
    "    secondary_category = classify(secondary_emotion)\n",
    "    \n",
    "    # 'neutral'이 포함된 경우는 별도 함수로 처리\n",
    "    if \"neutral\" in [primary_category, secondary_category] :\n",
    "        print(f\"Primary: {primary_category}, Secondary: {secondary_category}\")\n",
    "        return handle_neutral_case(primary_category, secondary_category)\n",
    "    \n",
    "    # 조건 비교 후 mode 반환\n",
    "    if primary_category == secondary_category in [\"positive\", \"negative\"]:\n",
    "        mode1 = \"유사색상\"\n",
    "        print(f\"Primary: {primary_category}, Secondary: {secondary_category}, Mode : {mode1}\")\n",
    "        return \"유사색상\"\n",
    "    else:\n",
    "        mode1 = \"유사색상\"\n",
    "        print(f\"Primary: {primary_category}, Secondary: {secondary_category}, Mode : {mode1}\")\n",
    "        return \"대비색상\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(emotion, df):\n",
    "    filtered = df[(df['감정 어휘'] == emotion) & (df['평가 순위'] == '1')]\n",
    "    filtered_df_array = filtered.to_dict(orient='records')\n",
    "\n",
    "    # (예외처리) 무작위로 하나 선택\n",
    "    if filtered_df_array:\n",
    "        return random.choice(filtered_df_array)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_info(top_ranked_value):\n",
    "    munsell_colors = ['R', 'YR', 'Y', 'GY', 'G', 'BG', 'B', 'PB', 'P', 'RP']\n",
    "    total = len(munsell_colors)\n",
    "\n",
    "    if top_ranked_value['색상약호'] not in munsell_colors:\n",
    "        return \"unknown_color\"\n",
    "    # 색상약호의 인덱스 찾기\n",
    "    idx = munsell_colors.index(top_ranked_value['색상약호'])\n",
    "\n",
    "    # 유사색상군\n",
    "    similar_1_idx = [(idx - 1) % total, (idx + 1) % total]\n",
    "    similar_2_idx = [(idx - 2) % total, (idx + 2) % total]\n",
    "\n",
    "    # 대비색상군\n",
    "    contrast_2_idx = [(idx - 3) % total, (idx + 3) % total]\n",
    "    contrast_1_idx = [(idx - 4) % total, (idx + 4) % total]\n",
    "    contrast_idx = [(idx - 5) % total]  # 보색 (정반대 5칸 거리)\n",
    "\n",
    "    # 변환\n",
    "    similar_colors_1 = [munsell_colors[i] for i in similar_1_idx]\n",
    "    similar_colors_2 = [munsell_colors[i] for i in similar_2_idx]\n",
    "    contrast_colors_2 = [munsell_colors[i] for i in contrast_2_idx]\n",
    "    contrast_colors_1 = [munsell_colors[i] for i in contrast_1_idx]\n",
    "    contrast_color = [munsell_colors[i] for i in contrast_idx]\n",
    "\n",
    "    return {\n",
    "        \"center_color\": top_ranked_value,\n",
    "        \"similar_colors_1\": similar_colors_1,\n",
    "        \"similar_colors_2\": similar_colors_2,\n",
    "        \"contrast_colors_1\": contrast_colors_1,\n",
    "        \"contrast_colors_2\": contrast_colors_2,\n",
    "        \"contrast_color\": contrast_color  # 보색\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_mapping(primary_color_info, secondary_emotion, df):\n",
    "    # secondary_ranked_value = df[df['감정 어휘'] == secondary_emotion].sort_values(by='평가 순위').iloc[0].to_dict()\n",
    "    secondary_ranked_df = df[df['감정 어휘'] == secondary_emotion]\n",
    "    \n",
    "    similar_matches_1 = []\n",
    "    similar_matches_2 = []\n",
    "    similar_match_exact = []\n",
    "\n",
    "            \n",
    "    # similar_colors_1 체크\n",
    "    for similar_color in primary_color_info['similar_colors_1']:\n",
    "        matched = secondary_ranked_df[secondary_ranked_df['색상약호'] == similar_color]\n",
    "        if not matched.empty:\n",
    "            similar_matches_1.append(matched)\n",
    "\n",
    "    # similar_colors_2 체크\n",
    "    for similar_color in primary_color_info['similar_colors_2']:\n",
    "        matched = secondary_ranked_df[secondary_ranked_df['색상약호'] == similar_color]\n",
    "        if not matched.empty:\n",
    "            similar_matches_2.append(matched)\n",
    "            \n",
    "    # same_color (동일색) 체크\n",
    "    same_color = primary_color_info['center_color']  # 단일 값 리스트 #주색은 미리 딕셔너리로 보관됨. 그대로 가져옴.\n",
    "    matched_exact = secondary_ranked_df[secondary_ranked_df['색상약호'] == same_color]\n",
    "    if not matched_exact.empty:\n",
    "        similar_match_exact.append(matched_exact)\n",
    "    \n",
    "    # 유사색상군1과 유사색상군2 중 하나라도 일치하는 경우.\n",
    "    if similar_matches_1 or similar_matches_2: \n",
    "        if similar_matches_1: # 대비색상군1을 우선 선정.\n",
    "            similar_matches_1_df = pd.concat(similar_matches_1).to_dict(orient='records')\n",
    "            # print(similar_matches_1_df)\n",
    "            return {\"primary_color\" : primary_color_info['center_color'],\n",
    "                    \"secondary_color\" : min(similar_matches_1_df, key=lambda x: x['평가 순위'])}\n",
    "        else: #대비색상군1이 없고, 대비색상군2가 있는 경우\n",
    "            similar_matches_2_df = pd.concat(similar_matches_2).to_dict(orient='records')\n",
    "            # print(similar_matches_2_df)\n",
    "            return {\"primary_color\" : primary_color_info['center_color'],\n",
    "                    \"secondary_color\" :min(similar_matches_2_df, key=lambda x: x['평가 순위'])}\n",
    "            \n",
    "    # 동일색이 있는경우\n",
    "    if similar_match_exact:\n",
    "        similar_dicts = similar_match_exact[0].to_dict(orient='records')\n",
    "        return {\"primary_color\" : primary_color_info['center_color'],\n",
    "                \"secondary_color\" : min(similar_dicts, key=lambda x: x['평가 순위'])} # '평가 순위'가 가장 높은 값 (숫자가 클수록 높은 순위라면 ↓)\n",
    "        \n",
    "    # 유사색상이 없는 경우\n",
    "    pure_secondary_colors = get_color(secondary_emotion, df)\n",
    "    return {\"primary_color\" : primary_color_info['center_color'], \"secondary_color\" :pure_secondary_colors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_mapping(primary_color_info, secondary_emotion, df):\n",
    "    secondary_ranked_df = df[df['감정 어휘'] == secondary_emotion]\n",
    "        \n",
    "    contrast_matches_1 = []\n",
    "    contrast_matches_2 = []\n",
    "    contrast_match_exact = []\n",
    "\n",
    "            \n",
    "    # contrast_colors_1 체크\n",
    "    for contrast_color in primary_color_info['contrast_colors_1']:\n",
    "        matched = secondary_ranked_df[secondary_ranked_df['색상약호'] == contrast_color]\n",
    "        if not matched.empty:\n",
    "            contrast_matches_1.append(matched)\n",
    "\n",
    "    # contrast_colors_2 체크\n",
    "    for contrast_color in primary_color_info['contrast_colors_2']:\n",
    "        matched = secondary_ranked_df[secondary_ranked_df['색상약호'] == contrast_color]\n",
    "        if not matched.empty:\n",
    "            contrast_matches_2.append(matched)\n",
    "            \n",
    "    # contrast_color (보색) 체크\n",
    "    contrast_color = primary_color_info['contrast_color'][0]  # 단일 값 리스트\n",
    "    matched_exact = secondary_ranked_df[secondary_ranked_df['색상약호'] == contrast_color]\n",
    "    if not matched_exact.empty:\n",
    "        contrast_match_exact.append(matched_exact)\n",
    "    \n",
    "    #보색이 정확히 일치하는 경우\n",
    "    if contrast_match_exact:\n",
    "        contrast_dicts = contrast_match_exact[0].to_dict(orient='records')\n",
    "        return {\"primary_color\" : primary_color_info['center_color'],\n",
    "                \"secondary_color\" : min(contrast_dicts, key=lambda x: x['평가 순위'])} # '평가 순위'가 가장 높은 값 (숫자가 클수록 높은 순위라면 ↓)\n",
    "    \n",
    "    # 대비색상군1과 대비색상군2 중 하나라도 일치하는 경우.\n",
    "    if contrast_matches_1 or contrast_matches_2: \n",
    "        if contrast_matches_1: # 대비색상군1을 우선 선정.\n",
    "            contrast_matches_1_df = pd.concat(contrast_matches_1).to_dict(orient='records')\n",
    "            # print(contrast_matches_1_df)\n",
    "            return {\"primary_color\" : primary_color_info['center_color'],\n",
    "                    \"secondary_color\" : min(contrast_matches_1_df, key=lambda x: x['평가 순위'])}\n",
    "        else: #대비색상군1이 없고, 대비색상군2가 있는 경우\n",
    "            contrast_matches_2_df = pd.concat(contrast_matches_2).to_dict(orient='records')\n",
    "            # print(contrast_matches_2_df)\n",
    "            return {\"primary_color\" : primary_color_info['center_color'],\n",
    "                    \"secondary_color\" :min(contrast_matches_2_df, key=lambda x: x['평가 순위'])}\n",
    "    # 대비색상이 없는 경우\n",
    "    pure_secondary_colors = get_color(secondary_emotion, df)\n",
    "    return {\"primary_color\" : primary_color_info['center_color'], \"secondary_color\" :pure_secondary_colors}  # '평가 순위'가 가장 높은 값 (숫자가 클수록 높은 순위라면 ↓)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sencondary_color(primary_color_info, secondary_emotion, mode_colors, df):\n",
    "    # 유사색상 모드일 때\n",
    "    if mode_colors == \"유사색상\":\n",
    "        return similar_mapping(primary_color_info, secondary_emotion, df)\n",
    "    # 대비색상 모드일 때\n",
    "    elif mode_colors == \"대비색상\": \n",
    "        return contrast_mapping(primary_color_info, secondary_emotion, df)\n",
    "        \n",
    "    # 예외처리 : 대비색상, 대비색상군1, 대비색상군2가 전부 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def define_colors(primary_emotion, secondary_emotion, df):\n",
    "#     mode_colors = categorize_emotion(primary_emotion, secondary_emotion)\n",
    "#     # top_ranked_value = df[df['감정 어휘'] == primary_emotion].sort_values(by='평가 순위').iloc[0].to_dict()\n",
    "#     # top_ranked_value = df[df['감정 어휘'] == primary_emotion].sort_values(by='평가 순위')\n",
    "#     # filtered = df[(df['감정 어휘'] == primary_emotion) & (df['평가 순위'] == 1)]\n",
    "    \n",
    "#     primary_color_data = get_color(primary_emotion, df) # 무작위로 하나 선택\n",
    "#     primary_color_info_test= get_primary_color(primary_color_data)\n",
    "#     return get_sencondary_color(primary_color_info_test, secondary_emotion, mode_colors, df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors_similar = define_colors(top_emotions_similar[0],top_emotions_similar[1], df) # 주감정과 보조감정, KCoED 데이터셋\n",
    "# colors_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors_similar_contrast = define_colors(top_emotions_similaremotion_contrastcolor[0],top_emotions_similaremotion_contrastcolor[1], df) # 주감정과 보조감정, KCoED 데이터셋\n",
    "# colors_similar_contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주색/보조색을 가지고 컬러 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hsb(rgb_dict):\n",
    "    # 문자열 RGB 값을 정수로 변환\n",
    "    r = int(rgb_dict['R']) / 255.0\n",
    "    g = int(rgb_dict['G']) / 255.0\n",
    "    b = int(rgb_dict['B']) / 255.0\n",
    "\n",
    "    # RGB → HSB (HSV)\n",
    "    h, s, v = colorsys.rgb_to_hsv(r, g, b)\n",
    "\n",
    "    # HSB 값 반환 (0~360, 0~100, 0~100)\n",
    "    return {\n",
    "        'H': round(h * 360), #반올림\n",
    "        'S': round(s * 100),\n",
    "        'B': round(v * 100),\n",
    "        'color info' : rgb_dict\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_primary_color1 = rgb_to_hsb(colors_similar['primary_color'])\n",
    "# processed_secondary_color1 = rgb_to_hsb(colors_similar['secondary_color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_primary_color2 = rgb_to_hsb(colors_contrast['primary_color'])\n",
    "# processed_secondary_color2 = rgb_to_hsb(colors_contrast['secondary_color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_primary_color3 = rgb_to_hsb(colors_similar_contrast['primary_color'])\n",
    "# processed_secondary_color3 = rgb_to_hsb(colors_similar_contrast['secondary_color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 형용사 정리 (버그수정)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추출한 감정형용사의 형용사군 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adjective_group(adjective, grouped_dict):\n",
    "    \"\"\"\n",
    "    주어진 형용사가 속한 형용사군(key)을 반환.\n",
    "    \"\"\"\n",
    "    for group, adjectives in grouped_dict.items():\n",
    "        if adjective in adjectives:\n",
    "            return group\n",
    "    return None  # 못 찾았을 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형용사 '사랑스러운'는 '귀여운' 형용사군에 속합니다.\n"
     ]
    }
   ],
   "source": [
    "group_name = find_adjective_group(result_IRI, grouped_adjectives)\n",
    "\n",
    "if group_name:\n",
    "    print(f\"형용사 '{result_IRI}'는 '{group_name}' 형용사군에 속합니다.\")\n",
    "else:\n",
    "    print(f\"형용사 '{result_IRI}'는 어떤 형용사군에도 속하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 배색그룹id: 2\n"
     ]
    }
   ],
   "source": [
    "IRI_colors_df = df_IRI_colors[df_IRI_colors['형용사군'] == group_name]\n",
    "# '배색그룹id' 컬럼에서 고유값만 추출\n",
    "palette_ids = IRI_colors_df['배색그룹id'].dropna().unique()\n",
    "\n",
    "# 랜덤 선택\n",
    "if len(palette_ids) > 0:\n",
    "    chosen_palette_id = random.choice(palette_ids)\n",
    "    print(f\"선택된 배색그룹id: {chosen_palette_id}\")\n",
    "else:\n",
    "    chosen_palette_id = None\n",
    "    print(\"배색그룹id가 존재하지 않습니다.\")\n",
    "    \n",
    "# chosen_palette_id에 해당하는 행만 추출\n",
    "palette_df = IRI_colors_df[IRI_colors_df['배색그룹id'] == chosen_palette_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_color_pair(palette_df):\n",
    "    # 사용할 쌍 정의 (우선순위 순서)\n",
    "    priority_pairs = [(1, 2), (2, 3), (2, 1), (3, 2)]\n",
    "    fallback_pairs = [(1, 3), (3, 1)]\n",
    "\n",
    "    # 현재 데이터프레임에 존재하는 단일색상 id 추출\n",
    "    available_ids = set(palette_df['단일색상 id'].dropna().astype(int).unique())\n",
    "\n",
    "    # 가능한 쌍 필터링\n",
    "    valid_priority_pairs = [pair for pair in priority_pairs if pair[0] in available_ids and pair[1] in available_ids]\n",
    "    valid_fallback_pairs = [pair for pair in fallback_pairs if pair[0] in available_ids and pair[1] in available_ids]\n",
    "\n",
    "    # 랜덤 선택\n",
    "    if valid_priority_pairs:\n",
    "        return random.choice(valid_priority_pairs)\n",
    "    elif valid_fallback_pairs:\n",
    "        return random.choice(valid_fallback_pairs)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette_dicts(palette_df):\n",
    "    \"\"\"\n",
    "    palette_result 튜플 (id1, id2)에 대해 해당하는 단일색상id 행을\n",
    "    각각 dictionary로 반환\n",
    "    \"\"\"\n",
    "    palette_result = choose_color_pair(palette_df)\n",
    "    id1, id2 = palette_result\n",
    "\n",
    "    # '단일색상 id' 컬럼이 float일 가능성 있으므로 int로 캐스팅\n",
    "    df_cast = palette_df.copy()\n",
    "    df_cast['단일색상 id'] = df_cast['단일색상 id'].astype(int)\n",
    "\n",
    "    # 각 색상 id에 대응하는 행 추출 후 dict 변환\n",
    "    primary_row = df_cast[df_cast['단일색상 id'] == id1].iloc[0].to_dict()\n",
    "    secondary_row = df_cast[df_cast['단일색상 id'] == id2].iloc[0].to_dict()\n",
    "\n",
    "    return {'primary_palette' : primary_row, 'secondary_palette' : secondary_row}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_result = get_palette_dicts(palette_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_saturation_brightness(processed_primary_color, processed_secondary_color, palette_result):\n",
    "    \"\"\"\n",
    "    processed_primary_color와 processed_secondary_color의 S, B 값을\n",
    "    palette_result의 S, B 값으로 업데이트합니다.\n",
    "    \"\"\"\n",
    "    processed_primary_color['S'] = palette_result['primary_palette']['Saturation']\n",
    "    processed_primary_color['B'] = palette_result['primary_palette']['Brightness']\n",
    "    processed_secondary_color['S'] = palette_result['secondary_palette']['Saturation']\n",
    "    processed_secondary_color['B'] = palette_result['secondary_palette']['Brightness']\n",
    "\n",
    "    return {'updated_primary_color': processed_primary_color,\n",
    "            'updated_secondary_color': processed_secondary_color\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_colors1 = update_saturation_brightness(processed_primary_color1, processed_secondary_color1, palette_result)\n",
    "# updated_colors2 = update_saturation_brightness(processed_primary_color2, processed_secondary_color2, palette_result)\n",
    "# updated_colors3 = update_saturation_brightness(processed_primary_color3, processed_secondary_color3, palette_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 감정 어휘 정리 (진행예정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_emotion_text(emotion_name):\n",
    "    if emotion_name == '기대감' :\n",
    "        return '기대하다'\n",
    "    else : \n",
    "        return emotion_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def define_colors(result_emotions, result_IRI, df, IRI_colors_df):\n",
    "    top_two_emotions = filter_emotions(result_emotions, result_IRI)\n",
    "    mode1 = categorize_emotion(top_two_emotions[0],top_two_emotions[1])\n",
    "    filtered_top_two_emotion = filter_emotion_text(top_two_emotions[0]) # 임시적용\n",
    "    primary_color = get_color(filtered_top_two_emotion, df) # 무작위로 하나 선택\n",
    "    primary_color_info_data = get_color_info(primary_color)\n",
    "    \n",
    "    selected_colors = get_sencondary_color(primary_color_info_data, top_two_emotions[1], mode1, df)\n",
    "    processed_primary_color = rgb_to_hsb(selected_colors['primary_color'])\n",
    "    processed_secondary_color = rgb_to_hsb(selected_colors['secondary_color'])\n",
    "    \n",
    "    group_name = find_adjective_group(result_IRI, grouped_adjectives)\n",
    "    if group_name:\n",
    "        print(f\"형용사 '{result_IRI}'는 '{group_name}' 형용사군에 속합니다.\")\n",
    "    else:\n",
    "        print(f\"형용사 '{result_IRI}'는 어떤 형용사군에도 속하지 않습니다.\")\n",
    "        \n",
    "    IRI_colors_df = df_IRI_colors[df_IRI_colors['형용사군'] == group_name]\n",
    "    # '배색그룹id' 컬럼에서 고유값만 추출\n",
    "    palette_ids = IRI_colors_df['배색그룹id'].dropna().unique()\n",
    "\n",
    "    # 랜덤 선택\n",
    "    if len(palette_ids) > 0:\n",
    "        chosen_palette_id = random.choice(palette_ids)\n",
    "        print(f\"선택된 배색그룹id: {chosen_palette_id}\")\n",
    "    else:\n",
    "        chosen_palette_id = None\n",
    "        print(\"배색그룹id가 존재하지 않습니다.\")\n",
    "    \n",
    "    # chosen_palette_id에 해당하는 행만 추출\n",
    "    palette_df = IRI_colors_df[IRI_colors_df['배색그룹id'] == chosen_palette_id]    \n",
    "    palette_result = get_palette_dicts(palette_df)\n",
    "    updated_colors = update_saturation_brightness(processed_primary_color, processed_secondary_color, palette_result)\n",
    "    updated_colors['primary_emotion'] = top_two_emotions[0]\n",
    "    updated_colors['secondary_emotion'] = top_two_emotions[1]\n",
    "    return updated_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary: negative, Secondary: positive, Mode : 유사색상\n",
      "형용사 '사랑스러운'는 '귀여운' 형용사군에 속합니다.\n",
      "선택된 배색그룹id: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'updated_primary_color': {'H': 214,\n",
       "  'S': '89',\n",
       "  'B': '93',\n",
       "  'color info': {'감정id': '24',\n",
       "   '감정 어휘': '슬픔',\n",
       "   '평가 순위': '1',\n",
       "   'R': '76',\n",
       "   'G': '87',\n",
       "   'B': '101',\n",
       "   '샘플': nan,\n",
       "   '출처/참고문헌': '김애경,and 오윤경. \"긍정 및 부정 정서어휘에 대한 색 반응 연구.\" 조형미디어학 19.1 (2016): 59-66.',\n",
       "   '출처/참고문헌2': 'https://gist.github.com/hidex7777/5268753',\n",
       "   '색상': '남색',\n",
       "   '색상약호': 'PB',\n",
       "   '색상 온도': 'Cold',\n",
       "   nan: nan}},\n",
       " 'updated_secondary_color': {'H': 51,\n",
       "  'S': '100',\n",
       "  'B': '94',\n",
       "  'color info': {'감정id': '17',\n",
       "   '감정 어휘': '기쁨',\n",
       "   '평가 순위': '1',\n",
       "   'R': '238',\n",
       "   'G': '201',\n",
       "   'B': '0',\n",
       "   '샘플': nan,\n",
       "   '출처/참고문헌': '김애경,and 오윤경. \"긍정 및 부정 정서어휘에 대한 색 반응 연구.\" 조형미디어학 19.1 (2016): 59-66.',\n",
       "   '출처/참고문헌2': 'https://gist.github.com/hidex7777/5268700',\n",
       "   '색상': '노랑',\n",
       "   '색상약호': 'Y',\n",
       "   '색상 온도': 'Warm',\n",
       "   nan: nan}},\n",
       " 'primary_emotion': '슬픔',\n",
       " 'secondary_emotion': '기쁨'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_contrast = define_colors(result_emotions_contrast, result_IRI, df, IRI_colors_df) # 주감정과 보조감정, KCoED 데이터셋\n",
    "colors_contrast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsb_to_rgb_tuple(hsb):\n",
    "    h = int(hsb['H']) / 360\n",
    "    s = int(hsb['S']) / 100\n",
    "    v = int(hsb['B']) / 100\n",
    "    r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "    return (r, g, b)  # matplotlib uses 0-1 float RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_to_colors(top_emotions, color_results):\n",
    "    plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "    # RGB 변환\n",
    "    rgb1 = hsb_to_rgb_tuple(color_results['updated_primary_color'])\n",
    "    rgb2 = hsb_to_rgb_tuple(color_results['updated_secondary_color'])\n",
    "\n",
    "    # Figure + GridSpec (7:3 비율)\n",
    "    fig = plt.figure(figsize=(7, 2))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[7, 3])\n",
    "\n",
    "    # Primary Color 영역 (7)\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax1.imshow([[rgb1]], aspect='auto')\n",
    "    ax1.set_title(\"Primary Color\", fontsize=10)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Secondary Color 영역 (3)\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "    ax2.imshow([[rgb2]], aspect='auto')\n",
    "    ax2.set_title(\"Secondary Color\", fontsize=10)\n",
    "    ax2.axis('off')\n",
    "\n",
    "    # 전체 제목\n",
    "    # plt.suptitle(f\"{top_emotions[2]}, {top_emotions[0]}과(와) {top_emotions[1]}\", fontsize=14)\n",
    "    # 그래프 아래 중앙에 제목 넣기\n",
    "    fig.text(\n",
    "        0.5, -0.05,  # x, y (0~1 기준, 아래로 -0.05)\n",
    "        f\"{top_emotions[2]}, {top_emotions[0]}과(와) {top_emotions[1]}\",\n",
    "        ha='center', va='top',\n",
    "        fontsize=14\n",
    ")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "    \n",
    "    print(top_emotions, color_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['슬픔', '기쁨', '사랑스러운'] {'updated_primary_color': {'H': 214, 'S': '89', 'B': '93', 'color info': {'감정id': '24', '감정 어휘': '슬픔', '평가 순위': '1', 'R': '76', 'G': '87', 'B': '101', '샘플': nan, '출처/참고문헌': '김애경,and 오윤경. \"긍정 및 부정 정서어휘에 대한 색 반응 연구.\" 조형미디어학 19.1 (2016): 59-66.', '출처/참고문헌2': 'https://gist.github.com/hidex7777/5268753', '색상': '남색', '색상약호': 'PB', '색상 온도': 'Cold', nan: nan}}, 'updated_secondary_color': {'H': 51, 'S': '100', 'B': '94', 'color info': {'감정id': '17', '감정 어휘': '기쁨', '평가 순위': '1', 'R': '238', 'G': '201', 'B': '0', '샘플': nan, '출처/참고문헌': '김애경,and 오윤경. \"긍정 및 부정 정서어휘에 대한 색 반응 연구.\" 조형미디어학 19.1 (2016): 59-66.', '출처/참고문헌2': 'https://gist.github.com/hidex7777/5268700', '색상': '노랑', '색상약호': 'Y', '색상 온도': 'Warm', nan: nan}}, 'primary_emotion': '슬픔', 'secondary_emotion': '기쁨'}\n"
     ]
    }
   ],
   "source": [
    "# emotion_to_colors(top_emotions_similar, updated_colors1)\n",
    "# emotion_to_colors(top_emotions_contrast, updated_colors2)\n",
    "# emotion_to_colors(top_emotions_similaremotion_contrastcolor, updated_colors3)\n",
    "emotion_to_colors(top_emotions_contrast, colors_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPoEM 감정분류 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.4.36)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.11.10)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.26.4)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.10.15)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.24.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.2.0)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.14-py3-none-any.whl (373 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.24.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m193.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, typing-inspection, typing-inspect, tenacity, python-dotenv, marshmallow, jsonpatch, httpx-sse, requests-toolbelt, dataclasses-json, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 jsonpatch-1.33 langchain-0.3.27 langchain-community-0.3.27 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langsmith-0.4.14 marshmallow-3.26.1 pydantic-settings-2.10.1 python-dotenv-1.1.1 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspect-0.9.0 typing-inspection-0.4.1 zstandard-0.24.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-core\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "import torch.nn as nn\n",
    "from transformers import ElectraModel, AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8303508ba514429b4c15c65af2c6290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/288 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a977995d9c194c53b4513ef3b96baa64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/514 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc871fa2c71a4e9a82f6e32b3d570f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820ec59901384ed199676b20403b16bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################\n",
    "# 토크나이저 로드\n",
    "###########################\n",
    "MODEL_NAME = \"beomi/KcELECTRA-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. 공통 전처리 함수 및 라벨 정의\n",
    "LABELS = ['불평/불만', '환영/호의', '감동/감탄', '지긋지긋', '고마움', '슬픔', '화남/분노', '존경', '기대감', '우쭐댐/무시함', '안타까움/실망', '비장함', '의심/불신', '뿌듯함', '편안/쾌적', '신기함/관심', '아껴주는', '부끄러움', '공포/무서움', '절망', '한심함', '역겨움/징그러움', '짜증', '어이없음', '없음', '패배/자기혐오', '귀찮음', '힘듦/지침', '즐거움/신남', '깨달음', '죄책감', '증오/혐오', '흐뭇함(귀여움/예쁨)', '당황/난처', '경악', '부담/안_내킴', '서러움', '재미없음', '불쌍함/연민', '놀람', '행복', '불안/걱정', '기쁨', '안심/신뢰']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4. Pytorch Lightning 모델(BaseTagger) 정의\n",
    "class BaseTagger(pl.LightningModule):\n",
    "    def __init__(self, model_name=MODEL_NAME, lr=2e-5, weight_decay=0.01,\n",
    "                 n_training_steps=None, n_warmup_steps=None, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.electra = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=self.hparams.dropout_rate),\n",
    "            nn.Linear(self.electra.config.hidden_size, len(LABELS))\n",
    "        )\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.electra(input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(output.last_hidden_state[:, 0, :])\n",
    "        probs = torch.sigmoid(logits)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(probs, labels)\n",
    "            return loss, probs\n",
    "        return None, probs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self(**batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, _ = self(**batch)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.n_warmup_steps,\n",
    "            num_training_steps=self.hparams.n_training_steps\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"step\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint path: ../model/best_model_B_minmax_0.2.ckpt\n"
     ]
    }
   ],
   "source": [
    "best_ckpt_path_poetry = '../model/best_model_B_minmax_0.2.ckpt' # Colab 경로에 맞게 수정\n",
    "print(\"Best checkpoint path:\", best_ckpt_path_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # True면 GPU 사용 가능\n",
    "print(torch.cuda.device_count())  # 사용 가능한 GPU 개수\n",
    "print(torch.cuda.current_device())  # 현재 활성화된 GPU ID\n",
    "print(torch.cuda.get_device_name(0))  # GPU 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0a0+ecf3bae40a.nv25.01 12.8\n",
      "True\n",
      "NVIDIA A100-PCIE-40GB\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__, torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.zeros(1, device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n"
     ]
    }
   ],
   "source": [
    "!echo $NVIDIA_DRIVER_CAPABILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_poetry = BaseTagger.load_from_checkpoint(best_ckpt_path_poetry, map_location=\"cpu\" )\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_model_poetry.to(\"cpu\")\n",
    "best_model_poetry.eval()\n",
    "best_model_poetry.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_emotion(sample_text):\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        sample_text,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 입력 텐서 또한 같은 device로 이동\n",
    "        input_ids = encoding[\"input_ids\"].to(device)\n",
    "        attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "        # forward\n",
    "        _, predictions = best_model_poetry(input_ids, attention_mask)  # best_model_poetry 사용\n",
    "\n",
    "    # 추론 결과를 CPU로 가져와 numpy로 변환\n",
    "    predictions = predictions.flatten().cpu().numpy()\n",
    "\n",
    "    # 결과를 딕셔너리로 저장 (숫자값으로 변환)\n",
    "    result_dict = {\n",
    "        label_name: float(round(score, 3))  # np.float32 -> float 변환\n",
    "        for label_name, score in zip(LABELS, predictions)\n",
    "        if score > THRESHOLD\n",
    "    }\n",
    "\n",
    "    return result_dict\n",
    "    # 예시 출력\n",
    "    # {'불안/걱정': 0.336, '슬픔': 0.311}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "미풍에 웃는 아침을 기원하련다\n",
    "\"\"\" # 송몽규 - 하늘과 더불어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 샘플 텍스트에 대한 감정분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m poem_emotions \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m poem_emotions\n",
      "Cell \u001b[0;32mIn[55], line 13\u001b[0m, in \u001b[0;36mclassify_emotion\u001b[0;34m(sample_text)\u001b[0m\n\u001b[1;32m      3\u001b[0m encoding \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[1;32m      4\u001b[0m     sample_text,\n\u001b[1;32m      5\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# 입력 텐서 또한 같은 device로 이동\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# forward\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "poem_emotions = classify_emotion(sample_text)\n",
    "poem_emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Langchain (Blossom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/bitsandbytes-0.45.4.dev0-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain in /home/work/.local/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /home/work/.local/lib/python3.12/site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /home/work/.local/lib/python3.12/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/work/.local/lib/python3.12/site-packages (from langchain) (0.4.13)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.4.36)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/work/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/work/.local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/work/.local/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/work/.local/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.chains import LLMChain\n",
    "# # from langchain.output_parsers import StrOutputParser\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "# import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blossom 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "\n",
    "# # 토크나이저 로드\n",
    "# tokenizer_bllossom = AutoTokenizer.from_pretrained(model_id)\n",
    "# tokenizer_bllossom.pad_token = tokenizer_bllossom.eos_token  # Blossom은 pad_token이 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16  # 또는 \"auto\"\n",
    "# )\n",
    "\n",
    "# # 2. 텍스트 생성 파이프라인\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer_bllossom,\n",
    "#     temperature=0.3, #\t생성의 무작위성 조절 계수\n",
    "#     top_p=0.9, # 누적 확률이 top_p 이하인 토큰들만 고려\n",
    "#     max_new_tokens=4, #한 번에 생성할 최대 토큰 수입니다. (입력 프롬프트 제외)\n",
    "#     repetition_penalty=1.5 # 반복되는 단어에 대한 페널티\n",
    "# )\n",
    "\n",
    "# # 3. LangChain용 LLM 래퍼\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KOSOLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c3912267394b8d82df3eb7f8f26c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_ID = \"yanolja/KoSOLAR-10.7B-v0.2\"\n",
    "CACHE_DIR = \"../model/KOSOLAR\"   # 바꿀 경로\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, cache_dir=CACHE_DIR,  use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16, # GPU가 bfloat16/float16 지원 없으면 torch.float32\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "device = model.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프롬프트 엔지니어링 (no Vectior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가벼운,가지런한,간편한,감각적인,감미로운,감성적인,강인한,강한,개성적인,거친,건실한,격식있는,견고한,고급스러운,그윽한,기능적인,기운찬,깊은,깔끔한,나이든,남성적인,넉넉한,다양한,단순한,단정한,달콤한,도시적인,돋보이는,동양적인,동적인,딱딱한,뛰어난,맑은,매끄러운,매력적인,멋진,무거운,밝은,보수적인,복잡한,부드러운,사랑스러운,상쾌한,새로운,서양적인,선명한,섬세한,성숙한,세련된,소박한,수수한,순수한,스포티한,시원한,신선한,실용적인,심플한,싱싱한,아기자기한,안정된,약한,얕은,어두운,여성적인,여유있는,연약한,오래된,와일드한,우울한,유연한,율동적인,이성적인,인공적인,자연적인,자유로운,잔잔한,장식적인,재미있는,전원적인,전통적인,젊은,정다운,정돈된,정적인,조용한,중후한,즐거운,지적인,진보적인,차가운,차분한,친근한,쾌활한,클래식한,탁한,투명한,편리한,편안한,포근한,품위있는,풍성한,하이테크한,한국적인,향기로운,혁신적인,환상적인,활동적인\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거 후 정렬\n",
    "adjectives = sorted(df_IRI['형용사'].dropna().unique())\n",
    "# 배열을 콤마 구분 문자열로 변환\n",
    "adjectives_str = \",\".join(adjectives)\n",
    "\n",
    "print(adjectives_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('가벼운', -6.84375), ('그윽한', -7.5), ('신선한', -7.625), ('와일드한', -7.84375), ('감미로운', -7.96875), ('깔끔한', -8.0), ('잔잔한', -8.0625), ('쾌활한', -8.0625), ('감성적인', -8.1875), ('동양적인', -8.1875), ('여유있는', -8.1875), ('기운찬', -8.25), ('조용한', -8.25), ('부드러운', -8.375), ('강인한', -8.5625), ('향기로운', -8.5625), ('단정한', -8.6875), ('건실한', -8.75), ('달콤한', -8.875), ('개성적인', -8.9375), ('싱싱한', -8.9375), ('간편한', -9.0), ('고급스러운', -9.0), ('아기자기한', -9.0), ('중후한', -9.0), ('즐거운', -9.0625), ('풍성한', -9.0625), ('환상적인', -9.125), ('심플한', -9.1875), ('여성적인', -9.1875), ('우울한', -9.25), ('스포티한', -9.3125), ('가지런한', -9.4375), ('수수한', -9.5), ('지적인', -9.5), ('섬세한', -9.5625), ('깊은', -9.6875), ('매끄러운', -9.6875), ('밝은', -9.6875), ('자유로운', -9.875), ('순수한', -9.9375), ('남성적인', -10.0), ('유연한', -10.0), ('동적인', -10.0625), ('무거운', -10.125), ('보수적인', -10.125), ('품위있는', -10.125), ('편안한', -10.25), ('돋보이는', -10.3125), ('포근한', -10.3125), ('자연적인', -10.375), ('차분한', -10.4375), ('서양적인', -10.5), ('어두운', -10.5), ('연약한', -10.5), ('오래된', -10.5), ('친근한', -10.5), ('한국적인', -10.5), ('정다운', -10.5625), ('성숙한', -10.6875), ('선명한', -10.75), ('소박한', -10.8125), ('활동적인', -10.9375), ('맑은', -11.0625), ('새로운', -11.0625), ('뛰어난', -11.1875), ('매력적인', -11.1875), ('상쾌한', -11.1875), ('도시적인', -11.25), ('장식적인', -11.3125), ('전원적인', -11.3125), ('감각적인', -11.375), ('멋진', -11.4375), ('재미있는', -11.5), ('다양한', -11.5625), ('젊은', -11.5625), ('복잡한', -11.625), ('사랑스러운', -11.625), ('안정된', -11.6875), ('격식있는', -11.75), ('정돈된', -11.75), ('클래식한', -11.75), ('견고한', -11.875), ('거친', -12.125), ('약한', -12.25), ('강한', -12.3125), ('넉넉한', -12.375), ('율동적인', -12.4375), ('시원한', -12.5), ('기능적인', -12.625), ('실용적인', -12.6875), ('투명한', -12.75), ('전통적인', -12.875), ('얕은', -12.9375), ('탁한', -13.0), ('딱딱한', -13.1875), ('이성적인', -13.375), ('세련된', -13.5), ('차가운', -13.5), ('정적인', -13.9375), ('단순한', -14.125), ('진보적인', -14.1875), ('혁신적인', -14.375), ('인공적인', -14.4375), ('하이테크한', -14.4375), ('나이든', -14.625), ('편리한', -15.875)]\n",
      "가벼운\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def score_labels_by_logprob(poem: str, labels: list[str], batch_size: int = 32):\n",
    "    # 프롬프트: '정답:' 뒤를 라벨로 채워넣어 점수화\n",
    "    base_prompt = (\n",
    "        \"너는 시를 읽는 독자야. 너는 주어진 시를 감상하고 시에 가장 의미적으로 어울리는 라벨 중 하나만 고른다\\n\"\n",
    "        f\"허용 라벨: {', '.join(labels)}\\n\\n시:\\n{poem}\\n\\n정답:\"\n",
    "    )\n",
    "    # 고정 프롬프트 길이(토큰)\n",
    "    prompt_ids = tok(base_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    prompt_len = prompt_ids.shape[1]\n",
    "\n",
    "    scores = []\n",
    "    # 배치로 후보 점수화 (전체 106개도 충분히 빠름)\n",
    "    for i in range(0, len(labels), batch_size):\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        texts = [base_prompt + lab for lab in batch_labels]\n",
    "        enc = tok(texts, return_tensors=\"pt\", padding=True).to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(**enc)\n",
    "            logits = out.logits  # [B, T, V]\n",
    "            logp = F.log_softmax(logits[:, :-1, :], dim=-1)     # predict next token\n",
    "            next_ids = enc.input_ids[:, 1:]                     # gold next tokens\n",
    "\n",
    "        # 각 샘플별로 '라벨 토큰' 구간만 합산\n",
    "        B, Tm1 = next_ids.shape\n",
    "        for b in range(B):\n",
    "            seq_len = enc.input_ids[b].shape[0]\n",
    "            label_tok_start = prompt_len - 1                    # 첫 예측 위치\n",
    "            label_tok_end   = seq_len - 1                       # 마지막 예측 위치(포함)\n",
    "            idx = torch.arange(Tm1, device=device)\n",
    "            mask = (idx >= label_tok_start) & (idx <= label_tok_end)\n",
    "            row_logp = logp[b].gather(-1, next_ids[b].unsqueeze(-1)).squeeze(-1)\n",
    "            score = row_logp[mask].sum().item()\n",
    "            scores.append((batch_labels[b], score))\n",
    "\n",
    "    # 점수 내림차순\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(scores)\n",
    "    return scores\n",
    "\n",
    "def classify_poem(poem: str, labels: list[str]) -> str:\n",
    "    scores = score_labels_by_logprob(poem, labels)\n",
    "    return scores[0][0]\n",
    "\n",
    "# # 예시\n",
    "# poem = \"미풍에 웃는 아칭을 기원하련다\"\n",
    "# print(classify_poem(poem, adjectives))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8️⃣ 전체 체인\n",
    "def CoReadingPoem(user_input, adjectives):\n",
    "    CoReading_Result = classify_poem(user_input, adjectives)\n",
    "    poem_colors = define_colors(poem_emotions, CoReading_Result , df, IRI_colors_df)\n",
    "    emotion_to_colors([poem_colors['primary_emotion'],poem_colors['secondary_emotion'], CoReading_Result], poem_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('가벼운', -6.15625), ('기운찬', -6.5625), ('신선한', -6.96875), ('그윽한', -7.25), ('감미로운', -7.5625), ('깔끔한', -7.5625), ('쾌활한', -7.6875), ('조용한', -7.75), ('감성적인', -7.78125), ('와일드한', -7.78125), ('잔잔한', -7.78125), ('밝은', -7.84375), ('부드러운', -7.84375), ('아기자기한', -8.0), ('싱싱한', -8.0625), ('강인한', -8.25), ('여유있는', -8.3125), ('단정한', -8.375), ('동양적인', -8.375), ('간편한', -8.4375), ('개성적인', -8.4375), ('건실한', -8.4375), ('향기로운', -8.75), ('고급스러운', -8.8125), ('심플한', -8.9375), ('즐거운', -8.9375), ('풍성한', -8.9375), ('환상적인', -8.9375), ('새로운', -9.0), ('달콤한', -9.0625), ('지적인', -9.0625), ('정다운', -9.125), ('중후한', -9.125), ('매끄러운', -9.1875), ('스포티한', -9.1875), ('포근한', -9.1875), ('맑은', -9.25), ('수수한', -9.25), ('여성적인', -9.25), ('우울한', -9.25), ('순수한', -9.3125), ('선명한', -9.5), ('섬세한', -9.5), ('깊은', -9.6875), ('상쾌한', -9.6875), ('자유로운', -9.75), ('동적인', -9.8125), ('성숙한', -9.8125), ('친근한', -9.9375), ('가지런한', -10.0), ('무거운', -10.0), ('오래된', -10.0), ('남성적인', -10.0625), ('소박한', -10.0625), ('편안한', -10.0625), ('서양적인', -10.1875), ('보수적인', -10.25), ('차분한', -10.25), ('돋보이는', -10.3125), ('품위있는', -10.3125), ('어두운', -10.4375), ('한국적인', -10.4375), ('유연한', -10.5), ('활동적인', -10.5625), ('연약한', -10.625), ('자연적인', -10.625), ('감각적인', -10.8125), ('사랑스러운', -10.8125), ('멋진', -10.875), ('정돈된', -11.0625), ('견고한', -11.125), ('안정된', -11.125), ('매력적인', -11.1875), ('전원적인', -11.25), ('다양한', -11.3125), ('젊은', -11.3125), ('도시적인', -11.375), ('약한', -11.375), ('재미있는', -11.375), ('장식적인', -11.4375), ('클래식한', -11.4375), ('뛰어난', -11.5), ('시원한', -11.5625), ('투명한', -11.9375), ('강한', -12.0), ('격식있는', -12.0), ('정적인', -12.0), ('탁한', -12.125), ('복잡한', -12.1875), ('얕은', -12.1875), ('세련된', -12.3125), ('거친', -12.375), ('실용적인', -12.5625), ('율동적인', -12.5625), ('전통적인', -12.5625), ('기능적인', -12.625), ('넉넉한', -12.6875), ('차가운', -12.6875), ('딱딱한', -12.8125), ('이성적인', -12.9375), ('하이테크한', -13.625), ('단순한', -14.25), ('인공적인', -14.3125), ('혁신적인', -14.6875), ('진보적인', -14.8125), ('편리한', -15.0), ('나이든', -15.125)]\n",
      "Primary: positive, Secondary: positive, Mode : 유사색상\n",
      "형용사 '가벼운'는 '맑은' 형용사군에 속합니다.\n",
      "선택된 배색그룹id: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['기대감', '기쁨', '가벼운'] {'updated_primary_color': {'H': 187, 'S': '20', 'B': '89', 'color info': {'감정id': '2', '감정 어휘': '기대하다', '평가 순위': '1', 'R': '84', 'G': '200', 'B': '216', '샘플': nan, '출처/참고문헌': '한국 성인의 감정 색채 반응 연구(한지운·나건, 2021)', '출처/참고문헌2': nan, '색상': '파랑', '색상약호': 'B', '색상 온도': 'Cold', nan: nan}}, 'updated_secondary_color': {'H': 51, 'S': '6', 'B': '85', 'color info': {'감정id': '17', '감정 어휘': '기쁨', '평가 순위': '1', 'R': '238', 'G': '201', 'B': '0', '샘플': nan, '출처/참고문헌': '김애경,and 오윤경. \"긍정 및 부정 정서어휘에 대한 색 반응 연구.\" 조형미디어학 19.1 (2016): 59-66.', '출처/참고문헌2': 'https://gist.github.com/hidex7777/5268700', '색상': '노랑', '색상약호': 'Y', '색상 온도': 'Warm', nan: nan}}, 'primary_emotion': '기대감', 'secondary_emotion': '기쁨'}\n"
     ]
    }
   ],
   "source": [
    "CoReadingPoem(sample_text, adjectives)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
